# Probabilistic generative models

**Capstone project for Imperial College London's course 'Probabilistic Deep Learning with TensorFlow 2' on Coursera.**

This notebook constructs generative models using normalising flow networks and the variational autoencoder algorithm. We create a synthetic dataset with a normalising flow with randomised parameters. This dataset is then used to train a variational autoencoder, with encoder compressing the data into vectors in R2, and decoder to generate new images from the learned distributions.

NOTE: The project instructions provided an outline for how to create the autoencoder. It also provided some helper functions for visualizing the data. These are specifically noted within the notebook.
